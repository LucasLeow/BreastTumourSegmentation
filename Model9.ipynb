{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3397092b",
   "metadata": {},
   "source": [
    "* Training with 64 x 64 x 32 cubes\n",
    "* Included train, validation & test dataset to test memory limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c513f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries -------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "import h5py\n",
    "import keras\n",
    "import loss\n",
    "import Helper\n",
    "import allMetrics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import UNetModel_3D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6819db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "try:\n",
    "  for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2111b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ae3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fileName = \"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/train_Scans/train_DS3.hdf5\"\n",
    "train_maskfileName = \"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/train_Mask_Scans/train_maskDS3.hdf5\"\n",
    "\n",
    "train_DatasetName = \"trainScans_DataSet3\"\n",
    "train_maskDatasetName = \"trainMaskScans_DataSet3\"\n",
    "\n",
    "\n",
    "valid_fileName = \"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/valid_Scans/valid_DS1.hdf5\"\n",
    "valid_maskfileName = \"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/valid_Mask_Scans/valid_maskDS1.hdf5\"\n",
    "\n",
    "valid_DatasetName = \"validScans_DataSet1\"\n",
    "valid_maskDatasetName = \"validMaskScans_DataSet1\"\n",
    "\n",
    "\n",
    "# test_fileName = \"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/test_Scans/test_DS1.hdf5\"\n",
    "# test_maskfileName = \"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/test_Mask_Scans/test_maskDS1.hdf5\"\n",
    "\n",
    "# test_DatasetName = \"testScans_DataSet1\"\n",
    "# test_maskDatasetName = \"testMaskScans_DataSet1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac1ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "with h5py.File(train_fileName, 'r') as hf: # File Dir\n",
    "    train_array = hf[train_DatasetName][:]\n",
    "    \n",
    "with h5py.File(train_maskfileName,'r') as hf:\n",
    "    train_mask_array = hf[train_maskDatasetName][:]\n",
    "    \n",
    "# Valid Dataset\n",
    "with h5py.File(valid_fileName, 'r') as hf: # File Dir\n",
    "    valid_array = hf[valid_DatasetName][:3375]\n",
    "    \n",
    "with h5py.File(valid_maskfileName,'r') as hf:\n",
    "    valid_mask_array = hf[valid_maskDatasetName][:3375]\n",
    "    \n",
    "# # Test Dataset\n",
    "# with h5py.File(test_fileName, 'r') as hf: # File Dir\n",
    "#     test_array = hf[test_DatasetName][:]\n",
    "    \n",
    "# with h5py.File(test_maskfileName,'r') as hf:\n",
    "#     test_mask_array = hf[test_maskDatasetName][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60ff809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23625, 64, 64, 32)\n",
      "(3375, 64, 64, 32)\n"
     ]
    }
   ],
   "source": [
    "print(train_array.shape)\n",
    "print(valid_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992627ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.expand_dims(train_array, axis=4)\n",
    "train_mask_array = np.expand_dims(train_mask_array, axis=4)\n",
    "\n",
    "valid_array = np.expand_dims(valid_array, axis=4)\n",
    "valid_mask_array = np.expand_dims(valid_mask_array, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba696749",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "opt = tf.keras.optimizers.Nadam(LR)\n",
    "\n",
    "input_shape = (64,64,32,1)\n",
    "num_class = 1\n",
    "\n",
    "metrics = [allMetrics.dice_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61fd20e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:34:03.007435: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 11:34:05.321550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38414 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2023-02-08 11:34:05.323532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38414 MB memory:  -> device: 1, name: A100-SXM4-40GB, pci bus id: 0000:47:00.0, compute capability: 8.0\n",
      "2023-02-08 11:34:05.325409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38414 MB memory:  -> device: 2, name: A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2023-02-08 11:34:05.327319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38414 MB memory:  -> device: 3, name: A100-SXM4-40GB, pci bus id: 0000:c2:00.0, compute capability: 8.0\n",
      "2023-02-08 11:34:05.328238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 2286 MB memory:  -> device: 4, name: DGX Display, pci bus id: 0000:c1:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 32,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 64, 64, 32,   896         ['input_1[0][0]']                \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 64, 32,   128        ['conv3d[0][0]']                 \n",
      " alization)                     32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 64, 64, 32,   0           ['batch_normalization[0][0]']    \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 64, 64, 32,   27680       ['leaky_re_lu[0][0]']            \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 64, 32,   128        ['conv3d_1[0][0]']               \n",
      " rmalization)                   32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 64, 64, 32,   0           ['batch_normalization_1[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 32, 32, 16,   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 32, 32, 16,   55360       ['max_pooling3d[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16,   256        ['conv3d_2[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 32, 32, 16,   0           ['batch_normalization_2[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 32, 32, 16,   110656      ['leaky_re_lu_2[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 16,   256        ['conv3d_3[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 32, 32, 16,   0           ['batch_normalization_3[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 16, 16, 8, 6  0          ['leaky_re_lu_3[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 16, 16, 8, 1  221312      ['max_pooling3d_1[0][0]']        \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 8, 1  512        ['conv3d_4[0][0]']               \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 16, 16, 8, 1  0           ['batch_normalization_4[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 16, 16, 8, 1  442496      ['leaky_re_lu_4[0][0]']          \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 8, 1  512        ['conv3d_5[0][0]']               \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 16, 16, 8, 1  0           ['batch_normalization_5[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 8, 8, 4, 128  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 8, 8, 4, 256  884992      ['max_pooling3d_2[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 4, 256  1024       ['conv3d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 8, 8, 4, 256  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 8, 8, 4, 256  1769728     ['leaky_re_lu_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 4, 256  1024       ['conv3d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 8, 8, 4, 256  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_3 (MaxPooling3D)  (None, 4, 4, 2, 256  0          ['leaky_re_lu_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 4, 4, 2, 512  3539456     ['max_pooling3d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 2, 512  2048       ['conv3d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 4, 4, 2, 512  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 4, 4, 2, 512  7078400     ['leaky_re_lu_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 4, 4, 2, 512  2048       ['conv3d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 4, 4, 2, 512  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_4 (MaxPooling3D)  (None, 2, 2, 1, 512  0          ['leaky_re_lu_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 2, 2, 1, 102  14156800    ['max_pooling3d_4[0][0]']        \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2, 2, 1, 102  4096       ['conv3d_10[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 2, 2, 1, 102  0           ['batch_normalization_10[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 2, 2, 1, 102  28312576    ['leaky_re_lu_10[0][0]']         \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 1, 102  4096       ['conv3d_11[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 2, 2, 1, 102  0           ['batch_normalization_11[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 4, 4, 2, 512  4194816    ['leaky_re_lu_11[0][0]']         \n",
      " ose)                           )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 4, 2, 102  0           ['conv3d_transpose[0][0]',       \n",
      "                                4)                                'leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 4, 4, 2, 512  14156288    ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 4, 2, 512  2048       ['conv3d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 4, 4, 2, 512  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 4, 4, 2, 512  7078400     ['leaky_re_lu_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 4, 4, 2, 512  2048       ['conv3d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 4, 4, 2, 512  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 8, 8, 4, 256  1048832    ['leaky_re_lu_13[0][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 4, 512  0           ['conv3d_transpose_1[0][0]',     \n",
      "                                )                                 'leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 8, 8, 4, 256  3539200     ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 4, 256  1024       ['conv3d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 8, 8, 4, 256  0           ['batch_normalization_14[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)             (None, 8, 8, 4, 256  1769728     ['leaky_re_lu_14[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 4, 256  1024       ['conv3d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 8, 8, 4, 256  0           ['batch_normalization_15[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 16, 16, 8, 1  262272     ['leaky_re_lu_15[0][0]']         \n",
      " spose)                         28)                                                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 16, 16, 8, 2  0           ['conv3d_transpose_2[0][0]',     \n",
      "                                56)                               'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)             (None, 16, 16, 8, 1  884864      ['concatenate_2[0][0]']          \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 8, 1  512        ['conv3d_16[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 16, 16, 8, 1  0           ['batch_normalization_16[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)             (None, 16, 16, 8, 1  442496      ['leaky_re_lu_16[0][0]']         \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 8, 1  512        ['conv3d_17[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 16, 16, 8, 1  0           ['batch_normalization_17[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_3 (Conv3DTran  (None, 32, 32, 16,   65600      ['leaky_re_lu_17[0][0]']         \n",
      " spose)                         64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 32, 16,   0           ['conv3d_transpose_3[0][0]',     \n",
      "                                128)                              'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_18 (Conv3D)             (None, 32, 32, 16,   221248      ['concatenate_3[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 16,   256        ['conv3d_18[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 32, 32, 16,   0           ['batch_normalization_18[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)             (None, 32, 32, 16,   110656      ['leaky_re_lu_18[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 32, 16,   256        ['conv3d_19[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 32, 32, 16,   0           ['batch_normalization_19[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_4 (Conv3DTran  (None, 64, 64, 32,   16416      ['leaky_re_lu_19[0][0]']         \n",
      " spose)                         32)                                                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 32,   0           ['conv3d_transpose_4[0][0]',     \n",
      "                                64)                               'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)             (None, 64, 64, 32,   55328       ['concatenate_4[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 64, 64, 32,   128        ['conv3d_20[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 64, 64, 32,   0           ['batch_normalization_20[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)             (None, 64, 64, 32,   27680       ['leaky_re_lu_20[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 64, 64, 32,   128        ['conv3d_21[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 64, 64, 32,   0           ['batch_normalization_21[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_22 (Conv3D)             (None, 64, 64, 32,   865         ['leaky_re_lu_21[0][0]']         \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 90,499,105\n",
      "Trainable params: 90,487,073\n",
      "Non-trainable params: 12,032\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = UNetModel_3D.build_unet(input_shape, n_classes = num_class)\n",
    "model.compile(optimizer=opt, loss=loss.tversky_crossentropy, metrics=metrics)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89cdfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/CSVLogs/Model9.csv'\n",
    "model_checkpoint_path = '/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2858ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, mode = 'auto'),\n",
    "    EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, mode = 'auto'),\n",
    "    CSVLogger(csv_path, separator=',', append=True),\n",
    "    ModelCheckpoint(filepath=model_checkpoint_path,\n",
    "                    monitor='val_loss',\n",
    "                    mode='auto',\n",
    "                    verbose=1,\n",
    "                    save_best_only= True)\n",
    "]\n",
    "#     CustomCallBack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c600b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:34:36.806360: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301\n",
      "2023-02-08 11:34:38.315213: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0175 - dice_coef: 0.0026\n",
      "Epoch 00001: val_loss improved from inf to 1.01610, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 370s 76ms/step - loss: 1.0175 - dice_coef: 0.0026 - val_loss: 1.0161 - val_dice_coef: 0.0075 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0135 - dice_coef: 0.0050\n",
      "Epoch 00002: val_loss improved from 1.01610 to 1.01334, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 357s 75ms/step - loss: 1.0135 - dice_coef: 0.0050 - val_loss: 1.0133 - val_dice_coef: 0.0099 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0102 - dice_coef: 0.0131\n",
      "Epoch 00003: val_loss improved from 1.01334 to 1.01196, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 1.0102 - dice_coef: 0.0131 - val_loss: 1.0120 - val_dice_coef: 0.0154 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0066 - dice_coef: 0.0216\n",
      "Epoch 00004: val_loss did not improve from 1.01196\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 1.0066 - dice_coef: 0.0216 - val_loss: 1.0145 - val_dice_coef: 0.0140 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0043 - dice_coef: 0.0277\n",
      "Epoch 00005: val_loss did not improve from 1.01196\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 1.0043 - dice_coef: 0.0277 - val_loss: 1.0237 - val_dice_coef: 0.0507 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0025 - dice_coef: 0.0334\n",
      "Epoch 00006: val_loss improved from 1.01196 to 1.00380, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 1.0025 - dice_coef: 0.0334 - val_loss: 1.0038 - val_dice_coef: 0.0234 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0013 - dice_coef: 0.0365\n",
      "Epoch 00007: val_loss did not improve from 1.00380\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 1.0013 - dice_coef: 0.0365 - val_loss: 1.0317 - val_dice_coef: 0.0166 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 1.0001 - dice_coef: 0.0412\n",
      "Epoch 00008: val_loss improved from 1.00380 to 0.99875, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 1.0001 - dice_coef: 0.0412 - val_loss: 0.9988 - val_dice_coef: 0.0389 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.9984 - dice_coef: 0.0453\n",
      "Epoch 00009: val_loss did not improve from 0.99875\n",
      "4725/4725 [==============================] - 355s 75ms/step - loss: 0.9984 - dice_coef: 0.0453 - val_loss: 1.0034 - val_dice_coef: 0.0608 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.9975 - dice_coef: 0.0484\n",
      "Epoch 00010: val_loss did not improve from 0.99875\n",
      "4725/4725 [==============================] - 355s 75ms/step - loss: 0.9975 - dice_coef: 0.0484 - val_loss: 0.9988 - val_dice_coef: 0.0542 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.9962 - dice_coef: 0.0531\n",
      "Epoch 00011: val_loss did not improve from 0.99875\n",
      "4725/4725 [==============================] - 355s 75ms/step - loss: 0.9962 - dice_coef: 0.0531 - val_loss: 1.0000 - val_dice_coef: 0.0663 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.9962 - dice_coef: 0.0531\n",
      "Epoch 00012: val_loss improved from 0.99875 to 0.99867, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 0.9962 - dice_coef: 0.0531 - val_loss: 0.9987 - val_dice_coef: 0.0749 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.9949 - dice_coef: 0.0581\n",
      "Epoch 00013: val_loss improved from 0.99867 to 0.99852, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 0.9949 - dice_coef: 0.0581 - val_loss: 0.9985 - val_dice_coef: 0.1512 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.9942 - dice_coef: 0.0619\n",
      "Epoch 00014: val_loss did not improve from 0.99852\n",
      "4725/4725 [==============================] - 355s 75ms/step - loss: 0.9942 - dice_coef: 0.0619 - val_loss: 1.0001 - val_dice_coef: 0.0760 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.9929 - dice_coef: 0.0655\n",
      "Epoch 00015: val_loss improved from 0.99852 to 0.99597, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 0.9929 - dice_coef: 0.0655 - val_loss: 0.9960 - val_dice_coef: 0.0617 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.8944 - dice_coef: 0.1517\n",
      "Epoch 00016: val_loss improved from 0.99597 to 0.11727, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 357s 76ms/step - loss: 0.8944 - dice_coef: 0.1517 - val_loss: 0.1173 - val_dice_coef: 0.9067 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0984 - dice_coef: 0.8357\n",
      "Epoch 00017: val_loss improved from 0.11727 to 0.10714, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 357s 76ms/step - loss: 0.0984 - dice_coef: 0.8357 - val_loss: 0.1071 - val_dice_coef: 0.8896 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0919 - dice_coef: 0.8368\n",
      "Epoch 00018: val_loss improved from 0.10714 to 0.10299, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 0.0919 - dice_coef: 0.8368 - val_loss: 0.1030 - val_dice_coef: 0.9067 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0899 - dice_coef: 0.8399\n",
      "Epoch 00019: val_loss improved from 0.10299 to 0.09626, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 0.0899 - dice_coef: 0.8399 - val_loss: 0.0963 - val_dice_coef: 0.9080 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0887 - dice_coef: 0.8317\n",
      "Epoch 00020: val_loss did not improve from 0.09626\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0887 - dice_coef: 0.8317 - val_loss: 0.1013 - val_dice_coef: 0.9067 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0872 - dice_coef: 0.8347\n",
      "Epoch 00021: val_loss did not improve from 0.09626\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0872 - dice_coef: 0.8347 - val_loss: 0.0987 - val_dice_coef: 0.9069 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0884 - dice_coef: 0.8351\n",
      "Epoch 00022: val_loss improved from 0.09626 to 0.08867, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 0.0884 - dice_coef: 0.8351 - val_loss: 0.0887 - val_dice_coef: 0.9101 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0866 - dice_coef: 0.8351\n",
      "Epoch 00023: val_loss did not improve from 0.08867\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0866 - dice_coef: 0.8351 - val_loss: 0.1027 - val_dice_coef: 0.9069 - lr: 0.0010\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0850 - dice_coef: 0.8225\n",
      "Epoch 00024: val_loss did not improve from 0.08867\n",
      "4725/4725 [==============================] - 355s 75ms/step - loss: 0.0850 - dice_coef: 0.8225 - val_loss: 0.0982 - val_dice_coef: 0.9072 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0871 - dice_coef: 0.8442\n",
      "Epoch 00025: val_loss did not improve from 0.08867\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0871 - dice_coef: 0.8442 - val_loss: 0.1022 - val_dice_coef: 0.9067 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0892 - dice_coef: 0.8318\n",
      "Epoch 00026: val_loss did not improve from 0.08867\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0892 - dice_coef: 0.8318 - val_loss: 0.1118 - val_dice_coef: 0.8531 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0818 - dice_coef: 0.8232\n",
      "Epoch 00027: val_loss did not improve from 0.08867\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0818 - dice_coef: 0.8232 - val_loss: 0.1071 - val_dice_coef: 0.8385 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0780 - dice_coef: 0.8244\n",
      "Epoch 00028: val_loss improved from 0.08867 to 0.08349, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 355s 75ms/step - loss: 0.0780 - dice_coef: 0.8244 - val_loss: 0.0835 - val_dice_coef: 0.9119 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0768 - dice_coef: 0.8298\n",
      "Epoch 00029: val_loss did not improve from 0.08349\n",
      "4725/4725 [==============================] - 353s 75ms/step - loss: 0.0768 - dice_coef: 0.8298 - val_loss: 0.0896 - val_dice_coef: 0.9060 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0772 - dice_coef: 0.8281\n",
      "Epoch 00030: val_loss did not improve from 0.08349\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0772 - dice_coef: 0.8281 - val_loss: 0.1126 - val_dice_coef: 0.8875 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0784 - dice_coef: 0.8294\n",
      "Epoch 00031: val_loss improved from 0.08349 to 0.08103, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 356s 75ms/step - loss: 0.0784 - dice_coef: 0.8294 - val_loss: 0.0810 - val_dice_coef: 0.9177 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0757 - dice_coef: 0.8265\n",
      "Epoch 00032: val_loss did not improve from 0.08103\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0757 - dice_coef: 0.8265 - val_loss: 0.1043 - val_dice_coef: 0.8815 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0780 - dice_coef: 0.8292\n",
      "Epoch 00033: val_loss did not improve from 0.08103\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0780 - dice_coef: 0.8292 - val_loss: 0.1139 - val_dice_coef: 0.8569 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0805 - dice_coef: 0.8231\n",
      "Epoch 00034: val_loss did not improve from 0.08103\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0805 - dice_coef: 0.8231 - val_loss: 0.0975 - val_dice_coef: 0.9092 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0716 - dice_coef: 0.8419\n",
      "Epoch 00035: val_loss did not improve from 0.08103\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0716 - dice_coef: 0.8419 - val_loss: 0.0935 - val_dice_coef: 0.9074 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0715 - dice_coef: 0.8414\n",
      "Epoch 00036: val_loss did not improve from 0.08103\n",
      "4725/4725 [==============================] - 354s 75ms/step - loss: 0.0715 - dice_coef: 0.8414 - val_loss: 0.0826 - val_dice_coef: 0.9056 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0762 - dice_coef: 0.8466\n",
      "Epoch 00037: val_loss improved from 0.08103 to 0.07846, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model9.hdf5\n",
      "4725/4725 [==============================] - 357s 75ms/step - loss: 0.0762 - dice_coef: 0.8466 - val_loss: 0.0785 - val_dice_coef: 0.9160 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "4725/4725 [==============================] - ETA: 0s - loss: 0.0784 - dice_coef: 0.8409\n",
      "Epoch 00038: val_loss did not improve from 0.07846\n",
      "4725/4725 [==============================] - 355s 75ms/step - loss: 0.0784 - dice_coef: 0.8409 - val_loss: 0.0806 - val_dice_coef: 0.9119 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "4468/4725 [===========================>..] - ETA: 18s - loss: 0.0817 - dice_coef: 0.8395"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42648/3937499702.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Helper.telegram_bot_sendtext(f'Model {model_name} started training')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(train_array,\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mtrain_mask_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'Model9 (300 Epochs)'\n",
    "# Helper.telegram_bot_sendtext(f'Model {model_name} started training')\n",
    "\n",
    "history = model.fit(train_array,\n",
    "                    train_mask_array,\n",
    "                    batch_size=5,\n",
    "                    epochs=300,\n",
    "                    verbose=1,\n",
    "                    shuffle = True,\n",
    "                    validation_data=(valid_array, valid_mask_array),\n",
    "                    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c33c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5d08b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42648/372329670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot the training and validation IoU and loss at each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#plot the training and validation IoU and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['dice_coef']\n",
    "val_acc = history.history['val_dice_coef']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Dice')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
    "plt.title('Training and validation Dice')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744e129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
