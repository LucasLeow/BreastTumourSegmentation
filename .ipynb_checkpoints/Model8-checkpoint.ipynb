{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de941f1",
   "metadata": {},
   "source": [
    "* Model 8 is explored using DGX Station in NCCS\n",
    "* Trainining Data is from DS 2\n",
    "* Most accurate model, training for 299 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f1793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries -------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "import h5py\n",
    "import keras\n",
    "import loss\n",
    "import Helper\n",
    "import allMetrics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import UNetModel_3D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2279e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05349e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /media/dro/JHSeagate/FYP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75ce5d",
   "metadata": {},
   "source": [
    "### Retrieving Dataset\n",
    "* Input own path as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5cd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num = 2\n",
    "valid_dataset_num = 2\n",
    "\n",
    "train_fileName = f\"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/train_Scans/train_DS{dataset_num}.hdf5\"\n",
    "train_maskfileName = f\"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/train_Mask_Scans/train_maskDS{dataset_num}.hdf5\"\n",
    "\n",
    "train_DatasetName = f\"trainScans_DataSet{dataset_num}\"\n",
    "train_maskDatasetName = f\"trainMaskScans_DataSet{dataset_num}\"\n",
    "\n",
    "valid_fileName = f\"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/valid_Scans/valid_DS{valid_dataset_num}.hdf5\"\n",
    "valid_maskfileName = f\"/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/trials/numpyDatasets/numPyArrays/valid_Mask_Scans/valid_maskDS{valid_dataset_num}.hdf5\"\n",
    "\n",
    "valid_DatasetName = f\"validScans_DataSet{valid_dataset_num}\"\n",
    "valid_maskDatasetName = f\"validMaskScans_DataSet{valid_dataset_num}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29dba584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "with h5py.File(train_fileName, 'r') as hf: # File Dir\n",
    "    train_array = hf[train_DatasetName][:]\n",
    "    \n",
    "with h5py.File(train_maskfileName,'r') as hf:\n",
    "    train_mask_array = hf[train_maskDatasetName][:]\n",
    "    \n",
    "with h5py.File(valid_fileName, 'r') as hf: # File Dir\n",
    "    valid_array = hf[valid_DatasetName][:1350]\n",
    "    \n",
    "with h5py.File(valid_maskfileName,'r') as hf:\n",
    "    valid_mask_array = hf[valid_maskDatasetName][:1350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fcba8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7875, 64, 64, 96)\n",
      "(7875, 64, 64, 96)\n",
      "--\n",
      "(1350, 64, 64, 96)\n",
      "(1350, 64, 64, 96)\n"
     ]
    }
   ],
   "source": [
    "print(train_array.shape)\n",
    "print(train_mask_array.shape)\n",
    "print('--')\n",
    "print(valid_array.shape)\n",
    "print(valid_mask_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dba15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.expand_dims(train_array, axis=4)\n",
    "train_mask_array = np.expand_dims(train_mask_array, axis=4)\n",
    "\n",
    "valid_array = np.expand_dims(valid_array, axis=4)\n",
    "valid_mask_array = np.expand_dims(valid_mask_array, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67627790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7875, 64, 64, 96, 1)\n",
      "(7875, 64, 64, 96, 1)\n",
      "--\n",
      "(1350, 64, 64, 96, 1)\n",
      "(1350, 64, 64, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_array.shape)\n",
    "print(train_mask_array.shape)\n",
    "print('--')\n",
    "print(valid_array.shape)\n",
    "print(valid_mask_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f8ff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 14:49:15.298982: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 14:49:15.773597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38414 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:c2:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 96,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 64, 64, 96,   896         ['input_1[0][0]']                \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 64, 96,   128        ['conv3d[0][0]']                 \n",
      " alization)                     32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 64, 64, 96,   0           ['batch_normalization[0][0]']    \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 64, 64, 96,   27680       ['leaky_re_lu[0][0]']            \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 64, 96,   128        ['conv3d_1[0][0]']               \n",
      " rmalization)                   32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 64, 64, 96,   0           ['batch_normalization_1[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 32, 32, 48,   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 32, 32, 48,   55360       ['max_pooling3d[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 48,   256        ['conv3d_2[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 32, 32, 48,   0           ['batch_normalization_2[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 32, 32, 48,   110656      ['leaky_re_lu_2[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 48,   256        ['conv3d_3[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 32, 32, 48,   0           ['batch_normalization_3[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 16, 16, 24,   0          ['leaky_re_lu_3[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 16, 16, 24,   221312      ['max_pooling3d_1[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 24,   512        ['conv3d_4[0][0]']               \n",
      " rmalization)                   128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 16, 16, 24,   0           ['batch_normalization_4[0][0]']  \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 16, 16, 24,   442496      ['leaky_re_lu_4[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 24,   512        ['conv3d_5[0][0]']               \n",
      " rmalization)                   128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 16, 16, 24,   0           ['batch_normalization_5[0][0]']  \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 8, 8, 12, 12  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 8, 8, 12, 25  884992      ['max_pooling3d_2[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 12, 25  1024       ['conv3d_6[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 8, 8, 12, 25  0           ['batch_normalization_6[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 8, 8, 12, 25  1769728     ['leaky_re_lu_6[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 12, 25  1024       ['conv3d_7[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 8, 8, 12, 25  0           ['batch_normalization_7[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling3d_3 (MaxPooling3D)  (None, 4, 4, 6, 256  0          ['leaky_re_lu_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 4, 4, 6, 512  3539456     ['max_pooling3d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 6, 512  2048       ['conv3d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 4, 4, 6, 512  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 4, 4, 6, 512  7078400     ['leaky_re_lu_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 4, 4, 6, 512  2048       ['conv3d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 4, 4, 6, 512  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_4 (MaxPooling3D)  (None, 2, 2, 3, 512  0          ['leaky_re_lu_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 2, 2, 3, 102  14156800    ['max_pooling3d_4[0][0]']        \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 2, 2, 3, 102  4096       ['conv3d_10[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 2, 2, 3, 102  0           ['batch_normalization_10[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 2, 2, 3, 102  28312576    ['leaky_re_lu_10[0][0]']         \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 2, 2, 3, 102  4096       ['conv3d_11[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 2, 2, 3, 102  0           ['batch_normalization_11[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 4, 4, 6, 512  4194816    ['leaky_re_lu_11[0][0]']         \n",
      " ose)                           )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 4, 6, 102  0           ['conv3d_transpose[0][0]',       \n",
      "                                4)                                'leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 4, 4, 6, 512  14156288    ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 4, 6, 512  2048       ['conv3d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 4, 4, 6, 512  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 4, 4, 6, 512  7078400     ['leaky_re_lu_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 4, 4, 6, 512  2048       ['conv3d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 4, 4, 6, 512  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 8, 8, 12, 25  1048832    ['leaky_re_lu_13[0][0]']         \n",
      " spose)                         6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 12, 51  0           ['conv3d_transpose_1[0][0]',     \n",
      "                                2)                                'leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 8, 8, 12, 25  3539200     ['concatenate_1[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 12, 25  1024       ['conv3d_14[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 8, 8, 12, 25  0           ['batch_normalization_14[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)             (None, 8, 8, 12, 25  1769728     ['leaky_re_lu_14[0][0]']         \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 12, 25  1024       ['conv3d_15[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 8, 8, 12, 25  0           ['batch_normalization_15[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 16, 16, 24,   262272     ['leaky_re_lu_15[0][0]']         \n",
      " spose)                         128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 16, 16, 24,   0           ['conv3d_transpose_2[0][0]',     \n",
      "                                256)                              'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)             (None, 16, 16, 24,   884864      ['concatenate_2[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 24,   512        ['conv3d_16[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 16, 16, 24,   0           ['batch_normalization_16[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)             (None, 16, 16, 24,   442496      ['leaky_re_lu_16[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 24,   512        ['conv3d_17[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 16, 16, 24,   0           ['batch_normalization_17[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_3 (Conv3DTran  (None, 32, 32, 48,   65600      ['leaky_re_lu_17[0][0]']         \n",
      " spose)                         64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 32, 48,   0           ['conv3d_transpose_3[0][0]',     \n",
      "                                128)                              'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_18 (Conv3D)             (None, 32, 32, 48,   221248      ['concatenate_3[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 32, 48,   256        ['conv3d_18[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 32, 32, 48,   0           ['batch_normalization_18[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)             (None, 32, 32, 48,   110656      ['leaky_re_lu_18[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 32, 48,   256        ['conv3d_19[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 32, 32, 48,   0           ['batch_normalization_19[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_4 (Conv3DTran  (None, 64, 64, 96,   16416      ['leaky_re_lu_19[0][0]']         \n",
      " spose)                         32)                                                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 96,   0           ['conv3d_transpose_4[0][0]',     \n",
      "                                64)                               'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)             (None, 64, 64, 96,   55328       ['concatenate_4[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 64, 64, 96,   128        ['conv3d_20[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 64, 64, 96,   0           ['batch_normalization_20[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)             (None, 64, 64, 96,   27680       ['leaky_re_lu_20[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 64, 64, 96,   128        ['conv3d_21[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 64, 64, 96,   0           ['batch_normalization_21[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_22 (Conv3D)             (None, 64, 64, 96,   865         ['leaky_re_lu_21[0][0]']         \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 90,499,105\n",
      "Trainable params: 90,487,073\n",
      "Non-trainable params: 12,032\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "LR = 0.001\n",
    "opt = tf.keras.optimizers.Nadam(LR)\n",
    "\n",
    "input_shape = (64,64,96,1)\n",
    "num_class = 1\n",
    "\n",
    "metrics = [allMetrics.dice_coef]\n",
    "\n",
    "model = UNetModel_3D.build_unet(input_shape, n_classes = num_class)\n",
    "model.compile(optimizer=opt, loss=loss.tversky_crossentropy, metrics=metrics)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce219a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55392e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCallBack(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs = None):\n",
    "#         lr = self.model.optimizer.lr\n",
    "#         decay = self.model.optimizer.decay\n",
    "#         iterations = self.model.optimizer.iterations\n",
    "#         lr_with_decay = lr / (1. + decay * K.cast(iterations, K.dtype(decay)))\n",
    "\n",
    "#         Helper.telegram_bot_sendtext(f'''\n",
    "#                             End of Epoch {epoch}\n",
    "#                             Train Dice: {logs.get(\"dice_coef\")}\n",
    "#                             Valid Dice: {logs.get(\"val_dice_coef\")}\n",
    "#                             Train Loss: {logs.get(\"loss\")}\n",
    "#                             Val Loss: {logs.get('val_loss')}\n",
    "#                             LR: {lr_with_decay}\n",
    "#                               ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4254afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/tester/jianhoong # ntu\n",
    "# /media/dro/JHSeagate/FYP/ # dgx\n",
    "\n",
    "csv_path = '/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/CSVLogs/Model8_run2.csv'\n",
    "model_checkpoint_path = '/media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7abf0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode = 'auto'),\n",
    "    EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True, mode = 'auto'),\n",
    "    CSVLogger(csv_path, separator=',', append=True),\n",
    "    ModelCheckpoint(filepath=model_checkpoint_path,\n",
    "                    monitor='val_loss',\n",
    "                    mode='auto',\n",
    "                    verbose=1,\n",
    "                    save_best_only= True)\n",
    "]\n",
    "#     CustomCallBack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9005097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 14:49:49.627966: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301\n",
      "2023-03-02 14:49:50.486748: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - ETA: 0s - loss: 1.0179 - dice_coef: 0.0096\n",
      "Epoch 00001: val_loss improved from inf to 1.02618, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 265s 162ms/step - loss: 1.0179 - dice_coef: 0.0096 - val_loss: 1.0262 - val_dice_coef: 0.0041 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 1.0086 - dice_coef: 0.0198\n",
      "Epoch 00002: val_loss improved from 1.02618 to 1.02480, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 159ms/step - loss: 1.0086 - dice_coef: 0.0198 - val_loss: 1.0248 - val_dice_coef: 0.0049 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9986 - dice_coef: 0.0483\n",
      "Epoch 00003: val_loss improved from 1.02480 to 1.02174, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 158ms/step - loss: 0.9986 - dice_coef: 0.0483 - val_loss: 1.0217 - val_dice_coef: 0.0147 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9900 - dice_coef: 0.0756\n",
      "Epoch 00004: val_loss improved from 1.02174 to 0.99599, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 159ms/step - loss: 0.9900 - dice_coef: 0.0756 - val_loss: 0.9960 - val_dice_coef: 0.0461 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9850 - dice_coef: 0.0917\n",
      "Epoch 00005: val_loss improved from 0.99599 to 0.98002, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 159ms/step - loss: 0.9850 - dice_coef: 0.0917 - val_loss: 0.9800 - val_dice_coef: 0.0637 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9818 - dice_coef: 0.1022\n",
      "Epoch 00006: val_loss did not improve from 0.98002\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9818 - dice_coef: 0.1022 - val_loss: 0.9967 - val_dice_coef: 0.0602 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9788 - dice_coef: 0.1144\n",
      "Epoch 00007: val_loss improved from 0.98002 to 0.97741, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 159ms/step - loss: 0.9788 - dice_coef: 0.1144 - val_loss: 0.9774 - val_dice_coef: 0.0740 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9781 - dice_coef: 0.1212\n",
      "Epoch 00008: val_loss improved from 0.97741 to 0.97528, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 159ms/step - loss: 0.9781 - dice_coef: 0.1212 - val_loss: 0.9753 - val_dice_coef: 0.0653 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9758 - dice_coef: 0.1247\n",
      "Epoch 00009: val_loss did not improve from 0.97528\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9758 - dice_coef: 0.1247 - val_loss: 1.0087 - val_dice_coef: 0.0259 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9740 - dice_coef: 0.1331\n",
      "Epoch 00010: val_loss did not improve from 0.97528\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9740 - dice_coef: 0.1331 - val_loss: 1.0130 - val_dice_coef: 0.0670 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9734 - dice_coef: 0.1372\n",
      "Epoch 00011: val_loss improved from 0.97528 to 0.96489, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 251s 159ms/step - loss: 0.9734 - dice_coef: 0.1372 - val_loss: 0.9649 - val_dice_coef: 0.0870 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9710 - dice_coef: 0.1445\n",
      "Epoch 00012: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9710 - dice_coef: 0.1445 - val_loss: 1.0345 - val_dice_coef: 0.0476 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9703 - dice_coef: 0.1493\n",
      "Epoch 00013: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9703 - dice_coef: 0.1493 - val_loss: 1.0525 - val_dice_coef: 0.0725 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9690 - dice_coef: 0.1522\n",
      "Epoch 00014: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9690 - dice_coef: 0.1522 - val_loss: 1.0073 - val_dice_coef: 0.0624 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9685 - dice_coef: 0.1537\n",
      "Epoch 00015: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 248s 157ms/step - loss: 0.9685 - dice_coef: 0.1537 - val_loss: 1.0488 - val_dice_coef: 0.0522 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9685 - dice_coef: 0.1549\n",
      "Epoch 00016: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 248s 157ms/step - loss: 0.9685 - dice_coef: 0.1549 - val_loss: 0.9770 - val_dice_coef: 0.0710 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9676 - dice_coef: 0.1585\n",
      "Epoch 00017: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 247s 157ms/step - loss: 0.9676 - dice_coef: 0.1585 - val_loss: 0.9961 - val_dice_coef: 0.0751 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9655 - dice_coef: 0.1653\n",
      "Epoch 00018: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 248s 157ms/step - loss: 0.9655 - dice_coef: 0.1653 - val_loss: 1.0183 - val_dice_coef: 0.0450 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9659 - dice_coef: 0.1685\n",
      "Epoch 00019: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9659 - dice_coef: 0.1685 - val_loss: 1.0469 - val_dice_coef: 0.0563 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9658 - dice_coef: 0.1658\n",
      "Epoch 00020: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9658 - dice_coef: 0.1658 - val_loss: 0.9720 - val_dice_coef: 0.0848 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9650 - dice_coef: 0.1697\n",
      "Epoch 00021: val_loss did not improve from 0.96489\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9650 - dice_coef: 0.1697 - val_loss: 1.0353 - val_dice_coef: 0.0773 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9611 - dice_coef: 0.1772\n",
      "Epoch 00022: val_loss improved from 0.96489 to 0.96377, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 159ms/step - loss: 0.9611 - dice_coef: 0.1772 - val_loss: 0.9638 - val_dice_coef: 0.1017 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9598 - dice_coef: 0.1811\n",
      "Epoch 00023: val_loss improved from 0.96377 to 0.96174, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n",
      "1575/1575 [==============================] - 250s 159ms/step - loss: 0.9598 - dice_coef: 0.1811 - val_loss: 0.9617 - val_dice_coef: 0.1086 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9589 - dice_coef: 0.1907\n",
      "Epoch 00024: val_loss improved from 0.96174 to 0.96104, saving model to /media/dro/JHSeagate/FYP/jh_fyp_work/3D_UNet/Final/SavedModels/Model8_run2.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1575/1575 [==============================] - 250s 159ms/step - loss: 0.9589 - dice_coef: 0.1907 - val_loss: 0.9610 - val_dice_coef: 0.1211 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9584 - dice_coef: 0.1985\n",
      "Epoch 00025: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9584 - dice_coef: 0.1985 - val_loss: 0.9649 - val_dice_coef: 0.1123 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9590 - dice_coef: 0.1952\n",
      "Epoch 00026: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9590 - dice_coef: 0.1952 - val_loss: 0.9664 - val_dice_coef: 0.1187 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9581 - dice_coef: 0.2057\n",
      "Epoch 00027: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 157ms/step - loss: 0.9581 - dice_coef: 0.2057 - val_loss: 0.9631 - val_dice_coef: 0.1237 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9581 - dice_coef: 0.2000\n",
      "Epoch 00028: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9581 - dice_coef: 0.2000 - val_loss: 0.9655 - val_dice_coef: 0.1188 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9577 - dice_coef: 0.2059\n",
      "Epoch 00029: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9577 - dice_coef: 0.2059 - val_loss: 0.9664 - val_dice_coef: 0.1451 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9575 - dice_coef: 0.2042\n",
      "Epoch 00030: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9575 - dice_coef: 0.2042 - val_loss: 0.9627 - val_dice_coef: 0.1340 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9572 - dice_coef: 0.2096\n",
      "Epoch 00031: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 157ms/step - loss: 0.9572 - dice_coef: 0.2096 - val_loss: 0.9692 - val_dice_coef: 0.1437 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9566 - dice_coef: 0.2193\n",
      "Epoch 00032: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9566 - dice_coef: 0.2193 - val_loss: 0.9677 - val_dice_coef: 0.1646 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9570 - dice_coef: 0.2123\n",
      "Epoch 00033: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9570 - dice_coef: 0.2123 - val_loss: 0.9757 - val_dice_coef: 0.1245 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9574 - dice_coef: 0.2220\n",
      "Epoch 00034: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9574 - dice_coef: 0.2220 - val_loss: 0.9706 - val_dice_coef: 0.1683 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9564 - dice_coef: 0.2227\n",
      "Epoch 00035: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9564 - dice_coef: 0.2227 - val_loss: 0.9698 - val_dice_coef: 0.1633 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9558 - dice_coef: 0.2294\n",
      "Epoch 00036: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9558 - dice_coef: 0.2294 - val_loss: 0.9698 - val_dice_coef: 0.1738 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9562 - dice_coef: 0.2191\n",
      "Epoch 00037: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9562 - dice_coef: 0.2191 - val_loss: 0.9699 - val_dice_coef: 0.1729 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9557 - dice_coef: 0.2282\n",
      "Epoch 00038: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9557 - dice_coef: 0.2282 - val_loss: 0.9685 - val_dice_coef: 0.1625 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9562 - dice_coef: 0.2275\n",
      "Epoch 00039: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 248s 158ms/step - loss: 0.9562 - dice_coef: 0.2275 - val_loss: 0.9700 - val_dice_coef: 0.1743 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9558 - dice_coef: 0.2308\n",
      "Epoch 00040: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9558 - dice_coef: 0.2308 - val_loss: 0.9700 - val_dice_coef: 0.1795 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9560 - dice_coef: 0.2292\n",
      "Epoch 00041: val_loss did not improve from 0.96104\n",
      "1575/1575 [==============================] - 249s 158ms/step - loss: 0.9560 - dice_coef: 0.2292 - val_loss: 0.9692 - val_dice_coef: 0.1877 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.9551 - dice_coef: 0.2293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37613/3166690779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Helper.telegram_bot_sendtext(f'Model {model_name} started training')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(train_array,\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mtrain_mask_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1252\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'Model8 (300 Epochs)'\n",
    "# Helper.telegram_bot_sendtext(f'Model {model_name} started training')\n",
    "\n",
    "history = model.fit(train_array,\n",
    "                    train_mask_array,\n",
    "                    batch_size=5,\n",
    "                    epochs=300,\n",
    "                    verbose=1,\n",
    "                    shuffle = True,\n",
    "                    validation_data=(valid_array, valid_mask_array),\n",
    "                    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984aaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8dd912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the training and validation IoU and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['dice_coef']\n",
    "val_acc = history.history['val_dice_coef']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Dice')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
    "plt.title('Training and validation Dice')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52303fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
